{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b><u>Services</h1></b></u>\n",
    "\n",
    "<b>The challenge</b>\n",
    "\n",
    "Imagine you're developing a Python-based web application deployed in a Kubernetes cluster. \n",
    "\n",
    "This application is composed of multiple components such as a web server, a caching layer, and a database, each running in separate Pods. These components need to communicate with each other to function properly, but there’s a wrinkle: Pods have ephemeral life cycles and their IP addresses can change dynamically due to reasons like scaling, rescheduling, or node failures. But this isn’t the only challenge you’re facing! \n",
    "<ul>\n",
    "<li>Imagine that your web server, for instance, was directly communicating with the database Pod using its Pod IP address. The server would need constant updates whenever this IP changes—a manual and error-prone process.\n",
    "\n",
    "<li>Furthermore, consider if your caching layer is designed to handle high traffic and hence is replicated into multiple Pods for load balancing. Now, your web server needs to distribute requests among all these cache Pods. Maintaining and managing direct communication with every single cache Pod by their individual IP addresses would be a daunting task, and an inefficient use of resources.\n",
    "\n",
    "<li>Plus, there's the issue of service discovery. Say your web server needs to connect with a new analytics service you've just launched. It would require an updated list of all the active Pods and their IP addresses for this service—a difficult and dynamic challenge.<br>\n",
    "\n",
    "What is a Python developer to do in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><u>Services to the rescue</h2></b></u>\n",
    "Fortunately, services come to the rescue in these scenarios. Services offer an abstraction layer over Pods. For starters, they provide a stable virtual IP and a DNS name for each set of related Pods (like your caching layer or database), and these remain constant regardless of the changes in the underlying Pods. So, your web server only needs to know this Service IP or DNS name, saving it from the ordeal of tracking and updating numerous changing Pod IPs.\n",
    "\n",
    "Furthermore, Services automatically set up load balancing. When your web server sends a request to the caching layer's Service, Kubernetes ensures the request is distributed evenly among all available caching Pods. This automatic load balancing allows for efficient use of resources and improved performance.\n",
    "\n",
    "In essence, a Service acts like a stable intermediary within the cluster. Instead of applications (like a front-end interface) directly addressing specific Pods, they communicate with the Service. The Service then ensures the request reaches the right backend Pods. This layer of abstraction streamlines intra-cluster communication, making the system more resilient and easier to manage—even as the underlying Pod configurations change dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><u>Types of Services</h2></b></u>\n",
    "Let's imagine that, with the basic challenges addressed, you've expanded your Python web application and it now includes a user interface, an API layer, a database, and an external third-party service. Different components of your application have different networking needs, and Kubernetes services, with their various types, can cater to these needs effectively.\n",
    "\n",
    "First, you have the ClusterIP service. This is the default type and serves as the go-to choice when you need to enable communication between components within the cluster. For example, your API layer and your database might need to communicate frequently, but these exchanges are internal to your application. A ClusterIP service would give you a stable, cluster-internal IP address to facilitate this communication.\n",
    "\n",
    "Next, you may want to expose your API layer to external clients. You could use a NodePort service for this purpose. It makes your API layer available on a specific port across all nodes in your cluster. With this setup, anyone with access to your node's IP address can communicate with your API layer by contacting the specified NodePort.\n",
    "\n",
    "However, a NodePort might not be enough if your application is hosted in a cloud environment and you need to handle large volumes of incoming traffic. A LoadBalancer service might be a better choice in this scenario. It exposes your service using your cloud provider's load balancer, distributing incoming traffic across your nodes, which is ideal for components like your user interface that might experience heavy traffic.\n",
    "\n",
    "Finally, you might be integrating an external third-party service into your application. Rather than expose this service directly within the cluster, you can use an ExternalName service. This gives you an alias for the external service that you can reference using a Kubernetes DNS name.\n",
    "\n",
    "In summary, Kubernetes provides different types of services tailored to various networking requirements:\n",
    "<ul>\n",
    "<li><b><u>ClusterIP:</b></u> Facilitates internal communication within the cluster\n",
    "\n",
    "<li><b><u>NodePort:</b></u> Enables external access to services at a static port across nodes\n",
    "\n",
    "<li><b><u>LoadBalancer:</b></u> Provides external access with load balancing, often used with cloud provider load balancers\n",
    "\n",
    "<li><b><u>ExternalName:</b></u> Serves as an alias for an external service, represented with a Kubernetes DNS name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><u>Other features</h2></b></u>\n",
    "\n",
    "So far we’ve just scratched the surface of services. There are several features that extend the capabilities of services and can be employed to address specific use cases within your application's networking requirements. <br>\n",
    "\n",
    "<ul>\n",
    "<li><b><u>Service discovery with DNS:</b></u> As your application grows, new services are added and existing ones might move around as they are scheduled onto different nodes. Kubernetes has a built-in DNS service to automatically assign domain names to services. For instance, your web server could reach the database simply by using its service name (e.g., database-service.default.svc.cluster.local), rather than hard-coding IP addresses.\n",
    "\n",
    "<li><b><u>Headless services:</b></u> Let's say you want to implement a distributed database that requires direct peer-to-peer communication. You can use a headless service for this. Unlike a standard service, a headless service doesn't provide load-balancing or a stable IP, but instead returns the IP addresses of its associated pods, enabling direct pod-to-pod communication.\n",
    "\n",
    "<li><b><u>Service topology:</b></u> Suppose your application is deployed in a multi-region environment, and you want to minimize latency by ensuring that requests are served by the nearest pods. Service topology comes to the rescue, allowing you to preferentially route traffic based on the network topology, such as the node, zone, or region.\n",
    "\n",
    "<li><b><u>External Traffic Policy:</b></u> If you want to preserve the client source IP for requests coming into your web server, you can set the External Traffic Policy to \"Local\". This routes the traffic directly to the Pods running on the node, bypassing the usual load balancing and ensuring the original client IP is preserved.\n",
    "\n",
    "<li><b><u>Session affinity (sticky sessions):</b></u> Suppose users log into your application, and their session data is stored locally on the server pod handling the request. To maintain this session data, you could enable session affinity on your service, so that all requests from a specific user are directed to the same pod.\n",
    "\n",
    "<li><b><u>Service slicing:</b></u> Imagine you're rolling out a new feature and want to test it with a subset of your users. Service Slicing enables you to direct traffic to different sets of pods based on custom labels, providing granular control over traffic routing for A/B testing or canary releases.\n",
    "\n",
    "<li><b><u>Connecting external databases:</b></u> Perhaps your application relies on an external database hosted outside the Kubernetes cluster. You can create a Service with the type ExternalName to reference this database. This allows your application to access the database using a DNS name without needing to know its IP address, providing a level of indirection and increasing the flexibility of your application configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "\n",
    "def create_service(api_instance, namespace, service_name, target_port, port, service_type):\n",
    "\t# Define the Service manifest based on the chosen Service type\n",
    "\tservice_manifest = {\n",
    "    \t\"apiVersion\": \"v1\",\n",
    "    \t\"kind\": \"Service\",\n",
    "    \t\"metadata\": {\"name\": service_name},\n",
    "    \t\"spec\": {\n",
    "        \t\"selector\": {\"app\": \"your-app-label\"},\n",
    "        \t\"ports\": [\n",
    "            \t{\"protocol\": \"TCP\", \"port\": port, \"targetPort\": target_port}\n",
    "        \t]\n",
    "    \t}\n",
    "\t}\n",
    "\n",
    "\tif service_type == \"ClusterIP\":\n",
    "    \t# No additional changes required for ClusterIP, it is the default type\n",
    "    \tpass\n",
    "\telif service_type == \"NodePort\":\n",
    "    \t# Set the NodePort field to expose the service on a specific port on each node\n",
    "    \tservice_manifest[\"spec\"][\"type\"] = \"NodePort\"\n",
    "\telif service_type == \"LoadBalancer\":\n",
    "    \t# Set the LoadBalancer type to get an external load balancer provisioned\n",
    "    \tservice_manifest[\"spec\"][\"type\"] = \"LoadBalancer\"\n",
    "\telif service_type == \"ExternalName\":\n",
    "    \t# Set the ExternalName type to create an alias for an external service\n",
    "    \tservice_manifest[\"spec\"][\"type\"] = \"ExternalName\"\n",
    "    \t# Set the externalName field to the DNS name of the external service\n",
    "    \tservice_manifest[\"spec\"][\"externalName\"] = \"my-external-service.example.com\"\n",
    "\n",
    "\tapi_response = api_instance.create_namespaced_service(\n",
    "    \tbody=service_manifest,\n",
    "    \tnamespace=namespace,\n",
    "\t)\n",
    "\tprint(f\"Service '{service_name}' created with type '{service_type}'. Status: {api_response.status}\")\n",
    "\n",
    "\n",
    "def list_services(api_instance, namespace):\n",
    "\tapi_response = api_instance.list_namespaced_service(namespace=namespace)\n",
    "\tprint(\"Existing Services:\")\n",
    "\tfor service in api_response.items:\n",
    "    \tprint(f\"Service Name: {service.metadata.name}, Type: {service.spec.type}\")\n",
    "\n",
    "\n",
    "def delete_service(api_instance, namespace, service_name):\n",
    "\tapi_response = api_instance.delete_namespaced_service(\n",
    "    \tname=service_name,\n",
    "    \tnamespace=namespace,\n",
    "\t)\n",
    "\tprint(f\"Service '{service_name}' deleted. Status: {api_response.status}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t# Load Kubernetes configuration (if running in-cluster, this might not be necessary)\n",
    "\tconfig.load_kube_config()\n",
    "\n",
    "\t# Create an instance of the Kubernetes API client\n",
    "\tv1 = client.CoreV1Api()\n",
    "\n",
    "\t# Define the namespace where the services will be created\n",
    "\tnamespace = \"default\"\n",
    "\n",
    "\t# Example: Create a ClusterIP Service\n",
    "\tcreate_service(v1, namespace, \"cluster-ip-service\", target_port=8080, port=80, service_type=\"ClusterIP\")\n",
    "\n",
    "\t# Example: Create a NodePort Service\n",
    "\tcreate_service(v1, namespace, \"node-port-service\", target_port=8080, port=30000, service_type=\"NodePort\")\n",
    "\n",
    "\t# Example: Create a LoadBalancer Service (Note: This requires a cloud provider supporting LoadBalancer)\n",
    "\tcreate_service(v1, namespace, \"load-balancer-service\", target_port=8080, port=80, service_type=\"LoadBalancer\")\n",
    "\n",
    "\t# Example: Create an ExternalName Service\n",
    "\tcreate_service(v1, namespace, \"external-name-service\", target_port=8080, port=80, service_type=\"ExternalName\")\n",
    "\n",
    "\t# List existing Services\n",
    "\tlist_services(v1, namespace)\n",
    "\n",
    "\t# Example: Delete a Service\n",
    "\tdelete_service(v1, namespace, \"external-name-service\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WorkArea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
